---
title: "GEOG 5023 Final Project"
author: "Isaiah Lyons-Galante & Caleb Schmitz"
date: "2023-04-17"
version: 2
output: html_document
---

## Setup Code
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load needed libraries
library(rdhs)
library(tidyverse)
library(haven)
library(sf)
library(gstat)
```

## Manual Working Directory Setup
1. Put this file in a folder called "code". This is your working directory (wd).
2. Ensure you have the folder in the wd called "exports"
3. Ensure you have a folder in the wd called "data"
4. Ensure you have the folder "SLHR7ADT" inside of data, unzipped
5. Ensure you have the folder "SLGE7AFL" inside of data, unzipped
6. Ensure you have the folders with the regional and national boundaries as written below
7. Run this code!

## Import Data
```{r}
# manually read in the stata file
sl19 <- read_dta('./data/SLHR7ADT/SLHR7AFL.DTA')
var_labels <- get_variable_labels(sl19)

# read in shapefiles of the country, regions, and survey clusters
# https://gis.stackexchange.com/questions/19064/opening-shapefile-in-r

# rad in the shapefile of the country
country <- read_sf(dsn = "./data/sdr_national_data_2023-04-17/shps", layer = "sdr_national_data_dhs_2019")
plot(country)

# read in the shapefile of regions
regions <- read_sf(dsn = "./data/sdr_subnational_boundaries_2023-04-17/shps", layer = "sdr_subnational_boundaries2")
plot(regions)

# read in shapefile of survey cluster coordinates
clusters <- read_sf(dsn = "./data/SLGE7AFL", layer = "SLGE7AFL")
plot(clusters)

# "hv001" in sl19 dataframe tells us which cluster number each household belongs to
# "DHSCLUST" in gps dataframe contains the cluster number
# "LATNUM" and "LONGNUM" contain the coordinates of each cluster
# we'll need to join these two dfs to create maps of the variables we're interested in
# https://sparkbyexamples.com/r-programming/how-to-do-left-join-in-r/
sl19gps <- merge(
      x=sl19, 
      y=clusters, 
      by.x="hv001", 
      by.y="DHSCLUST",
      all.x=TRUE)

# export useful data to exports folder
saveRDS(country, "./exports/country.rds")
saveRDS(regions, "./exports/regions.rds")
saveRDS(clusters, "./exports/clusters.rds")
saveRDS(var_labels, "./exports/var_labels.rds")
saveRDS(sl19, "./exports/sl19.rds")
saveRDS(sl19gps, "./exports/sl19gps.rds")

```
## Mapping Data for Exploration
```{r}

# Dropping all data with coordinates (0,0) 
plottable_df <- filter(sl19gps, LATNUM > 0)

# This is turning hv206 from"haven-labelled' class to numeric for compatability with geom_point function.
plottable_df$hv206 <- as.factor(plottable_df$hv206)

ggplot(data = regions) +
    geom_sf() +
    geom_point(data=plottable_df, aes(x=LONGNUM, y=LATNUM, color=hv206, alpha=0.3)) +
    scale_color_manual(values = c("1" = "yellow", "0" = "white"))+
    labs(color="Access to Electricity")+ 
    ggtitle('Household Access to Electricity in Sierra Leone') + 
    theme_minimal()+
    ggspatial::annotation_scale()+
    ggspatial::annotation_north_arrow(location = "tr", which_north = "true") +
    labs(y= "", x = "") +
    theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())
    theme(plot.title = element_text(size = 20))
    
    # We have a bit of a problem in that each cluster represents several families, so most likely we are just seeing one family per cluster which isn't necessarily representative. Perhaps a spatial interpolation method map would give a better overall impression of electricity availability.
    
    plottable_df$hv271 <- as.numeric(plottable_df$hv271)
    
    ggplot(data = regions) +
    geom_sf() +
    geom_point(data=plottable_df, aes(x=LONGNUM, y=LATNUM, color=(hv271))) +
       scale_color_gradient(low="white",
                     high="darkgreen", space ="Lab")+ 
    labs(color="Wealth Level")+ 
    ggtitle('Household Wealth Distribution in Sierra Leone') + 
    theme_minimal()+
    ggspatial::annotation_scale()+
    ggspatial::annotation_north_arrow(location = "tr", which_north = "true") +
    labs(y= "", x = "") +
    theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())
    theme(plot.title = element_text(size = 20))
    
```


## Clean up data (Part 1 - for EDA)

### Chop down to 56 variables of interest
```{r}
# read in shortened RDS
sl19 <- readRDS("./exports/sl19.rds")
var_lables <- readRDS("./exports/var_labels.rds")

# columns of interest
keep2names <- c("hv000","hv001","hv006","hv007","hv010","hv011","hv012","hv013","hv014","hv024","hv025","hv040","hv045c","hv201","hv204","hv205","hv206","hv207","hv208","hv209","hv210","hv211","hv212","hv213","hv214","hv215","hv216","hv217","hv219","hv220","hv221","hv226","hv227","hv230a","hv237","hv241","hv243a","hv243b","hv243c","hv243d","hv243e","hv244","hv245","hv246","hv246a","hv246b","hv246c","hv246d","hv246e","hv246f","hv247","hv270","hv271","hv270a","hv271a","hml1")

# filter
sl19keep <- sl19[,keep2names]
vars2keep <- var_labels[keep2names,]

library(tidyverse)
library(haven)
# convert certain columns to factors
factorCols <- c("hv000","hv001","hv006","hv007","hv024","hv025","hv045c","hv201","hv205","hv206","hv207","hv208","hv209","hv210","hv211","hv212","hv213","hv214","hv215","hv217","hv219","hv221","hv226","hv227","hv230a","hv237","hv241","hv243a","hv243b","hv243c","hv243d","hv243e","hv244","hv246","hv246a","hv246b","hv246c","hv246d","hv246e","hv246f","hv247","hv270","hv270a")
sl19keep <- sl19keep %>% mutate_at(factorCols, as.factor)

# export to RDS
saveRDS(vars2keep, "./exports/vars2keep.rds")
saveRDS(sl19keep, "./exports/sl19keep.rds")
```

## Summarize data

```{r}
# import data
sl19keep <- readRDS("./exports/sl19keep.rds")
n <- nrow(sl19keep)
```

Histograms
```{r}
# histograms

hist(sl19keep$hv040, main="Altitude (m)") # altitude in meters
plot(sl19keep$hv024, main="Region") # region
plot(sl19keep$hv045c, main="Native Language")

ilg_hist <- function(x, bins, label, fill) {
  return(ggplot() + 
      geom_histogram(aes(x), color="black", fill=fill, bins=bins) +
      xlab(label) +
      ylab("Count") +
      ggtitle(label) +
      theme_bw()
  )
}


household <- ilg_hist(sl19keep$hv012, 33, "# Household Members", "purple")
household
women <- ilg_hist(sl19keep$hv010, 11, "# Women aged 15-49", "purple")
women
men <- ilg_hist(sl19keep$hv011, 11, "# Men aged 15-49", "purple")
men
children <- ilg_hist(sl19keep$hv014, 10, "# Children under 5 y.o.", "purple")
children

altitude <- ilg_hist(sl19keep$hv040, 30, "Altitude", "blue")
altitude

timetowater <- ilg_hist(sl19keep$hv204, 30, "Time to Water Source", "darkgreen")
timetowater # filter out high "unknowns"
```

Bar Charts
```{r}

ilg_bar <- function(x, label, fill) {
  return(ggplot() + 
      geom_bar(aes(x), color="black", fill=fill) +
      xlab(label) +
      ylab("Count") +
      ggtitle(label) +
      theme_bw()
  )
}

region <- ilg_bar(sl19keep$hv024, "Region", "blue")
region

language <- ilg_bar(sl19keep$hv045c, "Language", "blue")
language

watersource <- ilg_bar(sl19keep$hv201, "Source of Drinking Water", "darkgreen")
watersource


```

Pie Charts
```{r}
# pie charts of asset ownership
elec <- sum(sl19keep$hv206 == "1")
radio <- sum(sl19keep$hv207 == "1")
tele <- sum(sl19keep$hv208 == "1")
fridge <- sum(sl19keep$hv209 == "1")
bicycle <- sum(sl19keep$hv210 == "1")
motorcycle <- sum(sl19keep$hv211 == "1")
car <- sum(sl19keep$hv212 == "1")

pie(c(elec, n-elec), labels = c("Yes", "No"), main="Have Electricity", col=c("purple","white"))
pie(c(radio, n-radio), labels = c("Yes", "No"), main="Have Radio", col=c("purple","white"))
pie(c(tele, n-tele), labels = c("Yes", "No"), main="Have Television", col=c("purple","white"))
pie(c(fridge, n-fridge), labels = c("Yes", "No"), main="Have Fridge", col=c("purple","white"))
pie(c(bicycle, n-bicycle), labels = c("Yes", "No"), main="Have Bicycle", col=c("purple","white"))
pie(c(motorcycle, n-motorcycle), labels = c("Yes", "No"), main="Have Motorcycle", col=c("purple","white"))
pie(c(car, n-car), labels = c("Yes", "No"), main="Have Car", col=c("purple","white"))
```

Multivariable Bar Chart
```{r}
# bar chart of asset ownership
counts <- c(elec,radio,tele,fridge,bicycle,motorcycle,car)
labels <- c("Electricity", "Radio", "Television", "Fridge", "Bicycle", "Motorcyle", "Car")
assets <- data.frame(asset=labels, count=counts)
ggplot(assets) +
  geom_bar(aes(y=count, x=asset), fill="purple", stat='identity') +
  ggtitle('Asset Ownership')+
  xlab('Asset') +
  ylab('Count') +
  ylim(0,15000) + 
  theme_bw() +
  scale_color_brewer(palette="Dark2")+
  geom_hline(yintercept=n, style="dashed", color="gray")
```


## Old Code Not Needed Anymore
```{r}
#### OLD CODE NO LONGER NEEDED, KEEPING FOR REFERENCE ##############

############### GET DATA FROM API
# # set credentials for accessing DHS API
# set_rdhs_config(email = "isaiah.lyons-galante@colorado.edu",
#                 project = "Machine Learning Class Project")
# 
# # figure out what DHS uses for country IDs
# ids <- dhs_countries(returnFields=c("CountryName", "DHS_CountryCode"))
# str(ids)
# 
# # find all surveys for Sierra Leone
# surveys <- dhs_surveys(countryIds = c("SL"),
#                        surveyType = "DHS",
#                        surveyYearStart = 2018)
# head(surveys)
# # desired survey ID = "SL2019DHS"
# 
# # find the datasets from this survey
# datasets <- dhs_datasets(surveyIds = surveys$SurveyId,
#                          fileFormat = "flat")
# head(datasets, n=20)
# # desired filename = SLHR7AFL.ZIP

##########################

# # RDHS way to manually read in file from the Zip folder
# # https://rdrr.io/cran/rdhs/man/read_dhs_dta.html
# df <- read_dhs_dta('./data/SLHR7ADT.zip', mode = "haven", all_lower = TRUE)
# 
# # manually read in the stata file
# library(haven)
# df <- read_dta('./data/SLHR7ADT/SLHR7AFL.DTA')
# 
# # read in .dbf file from coordinates
# library(foreign)
# gps <- read.dbf('./data/SLGE7AFL/SLGE7AFL.dbf', as.is = FALSE)
# # "hv001" in sl19 dataframe tells us which cluster number each household belongs to
# # "DHSCLUST" in gps dataframe contains the cluster number
# # "LATNUM" and "LONGNUM" contain the coordinates of each cluster
# # we'll need to join these two dfs to create maps of the variables we're interested in
# 
# # pull in the geometry of the regions from the survey
# geo <- dhs_geometry(
#  surveyIds = 'SL2019DHS',
#   all_results = TRUE
# )
# plot(geo)
```

## Cleaning Data (Part 2 - for spatial analysis)
```{r}
sl19gps <- readRDS("./exports/sl19gps.rds")
df <- sl19gps

# columns of interest
interestingColumns <- c("hv000","hv001","hv006","hv007","hv010","hv011","hv012","hv013","hv014","hv024","hv025","hv040","hv045c","hv201","hv204","hv205","hv206","hv207","hv208","hv209","hv210","hv211","hv212","hv213","hv214","hv215","hv216","hv217","hv219","hv220","hv221","hv226","hv227","hv230a","hv237","hv241","hv243a","hv243b","hv243c","hv243d","hv243e","hv244","hv245","hv246","hv246a","hv246b","hv246c","hv246d","hv246e","hv246f","hv247","hv270","hv271","hv270a","hv271a","hml1")
gpsColumns <- c("LATNUM", "LONGNUM", "geometry", "ALT_DEM", "DATUM", "DHSREGNA", "ADM1NAME", "DHSID")
keepColumns <- c(interestingColumns, gpsColumns)

# filter down columns
df <- df[,keepColumns]

# filter out 0 coordinates
df <- filter(df, LATNUM != 0)

# re-export
sl19clean <- df
saveRDS(sl19clean, "./exports/sl19clean.rds")
```

## Kriging/Variogram
```{r}
# In this block I am projecting the cluster points to a WGS84 projection for analysis

sl19clean <- readRDS("./exports/sl19clean.rds")
df <- sl19clean

# project the cluster points
coordinates(df) = c('LONGNUM', 'LATNUM')
proj4string(df) = CRS("+proj=longlat +datum=WGS84")
plottable_df_projected<- spTransform(df, CRS("+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))

saveRDS(plottable_df_projected, "./exports/plottable_df_projected.rds")
```

```{r}
# In this block I am projecting the regions polygons to a WGS84 projection for analysis

regions <- readRDS("./exports/regions.rds")
# project the region boundaries
regions_oultine <-as(regions, "Spatial")

proj4string(regions_oultine) = CRS("+proj=longlat +datum=WGS84")
regions_projected<- spTransform(regions_oultine, CRS("+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))

# In this next chunk I am making the grid for IDW and Kriging

regions_projected <- readRDS("./exports/regions_projected.rds")

# Making grid
kriging_grid <- SpatialPixels(SpatialPoints(makegrid(regions_projected, n=15000)), proj4string = proj4string(regions_projected))
# Applying grid to Sierra Leone
kriging_grid <- kriging_grid[regions_projected,]
plot(kriging_grid)

saveRDS(kriging_grid, "./exports/kriging_grid.rds")
saveRDS(regions_projected, "./exports/regions_projected.rds")
```
```{r}
plottable_df_projected <- readRDS("./exports/plottable_df_projected.rds")
df <- plottable_df_projected

kriging_grid <- readRDS("./exports/kriging_grid.rds")

# Inverse distance weighting
hv271.idw <- idw(formula = hv271 ~ 1, df, kriging_grid, idp = 2, nmax = 100)
plot(hv271.idw)

#Plotting variogram for sample data
# sample variogram based on Cressie method, it is often used to account for outliers
p.vgm <- variogram(hv271 ~ 1, df, cressie=T)
plot(p.vgm, type='l')

# Reference block to see variogram model options
vgm()
show.vgms()

# Initial estimates for nugget, sill, and range (4,300,000,000; 7,900,000,000; 60,000)

saveRDS(hv271.idw, "./exports/hv271_krig_plot.rds")

# Fitting sample variogram to a model

initModel = vgm(psill = 7900000000, "Sph", range = 60000, nugget = 4300000000)
p.fitSph <- fit.variogram(p.vgm, model = initModel)
plot(p.vgm, pch = 20, cex = 1.5, col = "black", ylab = "Semivariance", xlab = "Distance (m)", model = p.fitSph)

Model = vgm(psill = 7900000000, "Exp", range = 60000, nugget = 4300000000)
p.fitExp <- fit.variogram(p.vgm, model = Model)
plot(p.vgm, pch = 20, cex = 1.5, col = "black", ylab = "Semivariance", xlab = "Distance (m)", model = p.fitExp)

Model2 = vgm(psill = 7900000000, "Lin", range = 60000, nugget = 4300000000)
p.fitMat <- fit.variogram(p.vgm, model = Model2)
plot(p.vgm, pch = 20, cex = 1.5, col = "black", ylab = "Semivariance", xlab = "Distance (m)", model = p.fitMat)

# After trying a few variograms, it appears Spherical is the best model

# Kriging model

# This line below is to remove duplicate locations as described here: https://gis.stackexchange.com/questions/222192/r-gstat-krige-covariance-matrix-singular-at-location-5-88-47-4-0-skipping
df <- df[-zerodist(df)[,1],] 

krigSph <- krige(hv271 ~ 1, df, kriging_grid, model = p.fitSph)
plot(krigSph)

saveRDS(krigSph, "./exports/kriging_model1.rds")

# Evaluating accuracy with Cross Validation - commented out to run faster, but can be uncommented and run to evaluate

# cvKriging<-krige.cv(hv271~1, df, kriging_grid, model=p.fitSph)
# # get the RMSE
# rmse<-sqrt(mean(cvKriging$residual^2))
# rmse
# 
# cvKriging<-krige.cv(hv271~1, df, kriging_grid, model=p.fitExp)
# # get the RMSE
# rmse2<-sqrt(mean(cvKriging$residual^2))
# rmse2

# It turns ou the p.fitExp fits better than the p.fitSph so I am now going to make a kriging with p.fitExp

krigExp <- krige(hv271 ~ 1, df, kriging_grid, model = p.fitExp)
plot(krigExp)

saveRDS(krigSph, "./exports/better_kriging_model.rds")

```

## Spatial Regression
```{r}
# reread in dataframe
sl19clean <- readRDS("./exports/sl19clean.rds")
df <- sl19clean

# define columns to keep
assetColumns <- c("hv206","hv207","hv208","hv209","hv210","hv211","hv212","hv221","hv227","hv243a","hv243b","hv243c","hv243d","hv243e","hv246a","hv246b","hv246c","hv246d","hv246e","hv246f","hv247", "hv271")
gpsColumns <- c("LATNUM", "LONGNUM", "ALT_DEM")
srColumns <- c(assetColumns, gpsColumns)


# filter big data frame to just columns needed for this
df <- df[,srColumns]

# convert all columns to numeric
df <- as.data.frame(lapply(df, as.numeric)) 

# add geometry back in
df$geometry <- sl19clean$geometry

# filter out "unknown" or "missing" values from survey
df <- na.omit(df) # remove NA values
df <- df %>% filter(
  hv246a < 95 &
  hv246b < 95 &
  hv246c < 95 &
  hv246d < 95 &
  hv246e < 95 &
  hv246f < 95
)

# inspect df to ensure ranges make sense
summary(df)

# remove geometry again
geometry <- df$geometry
df = select(df, -geometry)

# basic linear model
basic_linear_model <- lm(hv271 ~ ., data=df)
summary(basic_linear_model)

# map residuals
df$geometry <- geometry
df$residuals <- residuals(basic_linear_model)

# to do DEBUG
# ggplot(df) + 
#   geom_sf(aes(fill=residuals, geometry=geometry), color="transparent") +
#   scale_fill_gradient2() +
#   ggtitle("Map of Model Residuals")

# define neighors
# queen <- poly2nb(df)
# ny_qw <- nb2listw(queen)
# 
# lm.morantest(ny.lm, ny_qw)
```

```{r}
# reread in dataframe
sl19clean <- readRDS("./exports/sl19clean.rds")
df <- sl19clean


# define columns to keep
assetColumns <- c("hv206","hv207","hv208","hv209","hv210","hv211","hv212","hv221","hv227","hv243a","hv243b","hv243c","hv243d","hv243e","hv246a","hv246b","hv246c","hv246d","hv246e","hv246f","hv247", "hv271")
gpsColumns <- c("LATNUM", "LONGNUM", "ALT_DEM")
srColumns <- c(assetColumns, gpsColumns)


# filter big data frame to just columns needed for this
df <- df[,srColumns]

# convert all columns to numeric
df <- as.data.frame(lapply(df, as.numeric)) 

# add geometry back in
df$geometry <- sl19clean$geometry

# filter out "unknown" or "missing" values from survey
df <- na.omit(df) # remove NA values
df <- df %>% filter(
  hv246a < 95 &
  hv246b < 95 &
  hv246c < 95 &
  hv246d < 95 &
  hv246e < 95 &
  hv246f < 95
)


# remove geometry again
geometry <- df$geometry
df = select(df, -geometry)

# aggregate data to cluster level, keep means of other variables
df <- aggregate.data.frame(df, list(lat = df$LATNUM, lon = df$LONGNUM), mean)
sl19clusters <- df

# read in country and regions
regions <- readRDS("./exports/regions.rds")
country <- readRDS("./exports/country.rds")

# convert the countries shapefile (sf) into SpatialPolygon (sp)
library(geojsonsf)
country.sp <- as(country, 'Spatial')

# create voronoi tesselation plot
library(ggvoronoi)
ggplot(df) +
  geom_voronoi(aes(lon, lat, fill=hv271), outline = country.sp) + 
  scale_fill_gradient(low="white", high="blue") +
  geom_sf(data=regions, fill=NA, color="black") +
  ggtitle("Voronoi Tesellation of Sierra Leone")

# create voronoi tesselation SpatialPolygon
areas.sp <- voronoi_polygon(df, x="lon", y="lat", outline = country.sp)

# convert voronoi SpatialPolygon to a shapefile
library(sf)
areas.sf <- st_as_sf(areas.sp)
plot(areas.sf)
ggplot(data=areas.sf) +
  geom_sf(aes(fill=hv271)) +
  scale_fill_gradient(low="white", high="navyblue") +
  ggtitle("Wealth Voronoi Tesellation of Sierra Leone #2") +
  theme_void()

ggplot(data=areas.sf) +
  geom_sf(aes(fill=hv206)) +
  scale_fill_gradient(low="white", high="orange") +
  ggtitle("% with Electricity Access in Sierra Leone") +
  theme_void()

# export area
saveRDS(areas.sf, "./exports/areas.rds")   
saveRDS(sl19clusters, "./exports/sl19clusters.rds")  
```





